{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0(1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PradyumnaGupta/Career_Con_2019_Surface/blob/master/Career_Con_2019_ANN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "CU5fHughCyvm",
        "colab_type": "code",
        "outputId": "ed966a6c-f6bf-4e43-fed4-9eacd46271ad",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files \n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e331f6c8-0727-4c4d-a1d4-c34f388a5e32\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e331f6c8-0727-4c4d-a1d4-c34f388a5e32\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving X_train.csv to X_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5C3ar9NF_0sV",
        "colab_type": "code",
        "outputId": "cfbdaeae-04f3-41f6-f9de-a89d05fa9212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "MMGvyDUwAz8Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AvAalyq5AvoW",
        "colab_type": "code",
        "outputId": "1336ceb6-d1ce-4e20-ffcb-d2b537b3dff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "data_X=pd.read_csv('X_train.csv')\n",
        "temp_X=data_X.copy()\n",
        "temp_X=temp_X.drop('row_id',axis=1)\n",
        "temp_X=temp_X.drop('series_id',axis=1)\n",
        "temp_X=temp_X.drop('measurement_number',axis=1)\n",
        "print(temp_X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(487680, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VutyT2kSB6Az",
        "colab_type": "code",
        "outputId": "20555d45-f098-4779-cc5b-8601e7b61206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "data_Y=pd.read_csv('y_train.csv')\n",
        "temp_Y=data_Y.copy()\n",
        "temp_Y=temp_Y.drop('series_id',axis=1)\n",
        "temp_Y=temp_Y.drop('group_id',axis=1)\n",
        "print(temp_Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3810, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TUGvoGn3CwkQ",
        "colab_type": "code",
        "outputId": "5cc341cd-96bb-4164-e91f-f5ab3db4ab7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder \n",
        "enc=OneHotEncoder(handle_unknown=\"ignore\")\n",
        "enc.fit(temp_Y)\n",
        "temp_Y=enc.transform(temp_Y).toarray()\n",
        "print(temp_Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3810, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8ttzAPU4M8Mc",
        "colab_type": "code",
        "outputId": "554ad0f8-0e21-46fb-c41e-e0c1ec5934f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "temp_Y=np.repeat(temp_Y,128,axis=0)\n",
        "print(temp_Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(487680, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5CaBlEPsNTSI",
        "colab_type": "code",
        "outputId": "25d29f55-b33b-4737-dc11-e0b72a3f069d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "shuffled_data=shuffle(np.append(temp_X,temp_Y,axis=1),random_state=0)\n",
        "temp_X=shuffled_data[:,0:10]\n",
        "temp_Y=shuffled_data[:,10:19]\n",
        "print(temp_X.shape)\n",
        "print(temp_Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(487680, 10)\n",
            "(487680, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "79TDP1-di_-m",
        "colab_type": "code",
        "outputId": "26636b74-14d2-47ea-f175-9288001148e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "#import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(temp_X,temp_Y,test_size=0.25,random_state=0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(365760, 10)\n",
            "(121920, 10)\n",
            "(365760, 9)\n",
            "(121920, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WDdKBdCqROJZ",
        "colab_type": "code",
        "outputId": "cac50cf0-9c18-4a77-aa9e-de7be4857503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.transform(X_test)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(365760, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PufIqDcDS0IS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_I_fclCSTO_1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier=Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WLfttNwnTSpM",
        "colab_type": "code",
        "outputId": "335711e7-f490-43d5-d6e5-a90e254e4ee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "classifier.add(Dense(output_dim=10,init=\"glorot_uniform\",activation=\"relu\",input_dim=10,kernel_regularizer=regularizers.l2(0.000001)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=10, kernel_regularizer=<keras.reg..., units=10, kernel_initializer=\"glorot_uniform\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "fbAW2rqvZtuF",
        "colab_type": "code",
        "outputId": "bbc6527f-c8d5-4bfe-f866-221db6eabd0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "classifier.add(Dense(output_dim=11,init=\"glorot_uniform\",activation=\"relu\",kernel_regularizer=regularizers.l2(0.000001)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=11, kernel_initializer=\"glorot_uniform\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y8uYcrwXZuQj",
        "colab_type": "code",
        "outputId": "febc4adc-c823-4418-db8a-59bfad0f6962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "classifier.add(Dense(output_dim=9,init=\"glorot_uniform\",activation=\"relu\",kernel_regularizer=regularizers.l2(0.000001)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=9, kernel_initializer=\"glorot_uniform\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "bA-aSOHTHRaO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#classifier.add(Dense(output_dim=10,init=\"glorot_uniform\",activation=\"relu\"))#,kernel_regularizer=regularizers.l2(0.000001)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gP3gdcwLIrxy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#classifier.add(Dense(output_dim=10,init=\"glorot_uniform\",activation=\"relu\"))#,kernel_regularizer=regularizers.l2(0.000001)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BrMEpQKIUDhG",
        "colab_type": "code",
        "outputId": "7521adc9-ca45-4268-8428-fc2f4d2b5086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "classifier.add(Dense(output_dim=9,init=\"glorot_uniform\",activation=\"softmax\"))#,kernel_regularizer=regularizers.l2(0.000001)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=9, kernel_initializer=\"glorot_uniform\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZWOAyfx3UwNd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer='nadam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GA7LTxhWVGUn",
        "colab_type": "code",
        "outputId": "2418377b-2f8f-46fc-d431-7be94c881606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5542
        }
      },
      "cell_type": "code",
      "source": [
        "classifier.fit(X_train,Y_train,batch_size=512,nb_epoch=150)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "365760/365760 [==============================] - 10s 26us/step - loss: 1.6472 - acc: 0.3849\n",
            "Epoch 2/150\n",
            "365760/365760 [==============================] - 6s 15us/step - loss: 1.2528 - acc: 0.5489\n",
            "Epoch 3/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 1.1170 - acc: 0.6039\n",
            "Epoch 4/150\n",
            "365760/365760 [==============================] - 6s 15us/step - loss: 1.0683 - acc: 0.6200\n",
            "Epoch 5/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 1.0425 - acc: 0.6249\n",
            "Epoch 6/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 1.0216 - acc: 0.6287\n",
            "Epoch 7/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 1.0049 - acc: 0.6327\n",
            "Epoch 8/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.9902 - acc: 0.6353\n",
            "Epoch 9/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.9778 - acc: 0.6376\n",
            "Epoch 10/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.9667 - acc: 0.6400\n",
            "Epoch 11/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.9558 - acc: 0.6429\n",
            "Epoch 12/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.9456 - acc: 0.6460\n",
            "Epoch 13/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.9352 - acc: 0.6495\n",
            "Epoch 14/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.9270 - acc: 0.6533\n",
            "Epoch 15/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.9195 - acc: 0.6547\n",
            "Epoch 16/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.9128 - acc: 0.6581\n",
            "Epoch 17/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.9065 - acc: 0.6609\n",
            "Epoch 18/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8997 - acc: 0.6657\n",
            "Epoch 19/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8929 - acc: 0.6681\n",
            "Epoch 20/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8873 - acc: 0.6705\n",
            "Epoch 21/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8823 - acc: 0.6727\n",
            "Epoch 22/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8775 - acc: 0.6746\n",
            "Epoch 23/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8729 - acc: 0.6763\n",
            "Epoch 24/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8675 - acc: 0.6772\n",
            "Epoch 25/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8627 - acc: 0.6799\n",
            "Epoch 26/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8579 - acc: 0.6815\n",
            "Epoch 27/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8535 - acc: 0.6835\n",
            "Epoch 28/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8500 - acc: 0.6855\n",
            "Epoch 29/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8463 - acc: 0.6875\n",
            "Epoch 30/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8426 - acc: 0.6889\n",
            "Epoch 31/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8393 - acc: 0.6907\n",
            "Epoch 32/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.8366 - acc: 0.6921\n",
            "Epoch 33/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8333 - acc: 0.6934\n",
            "Epoch 34/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8309 - acc: 0.6950\n",
            "Epoch 35/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8283 - acc: 0.6968\n",
            "Epoch 36/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8263 - acc: 0.6975\n",
            "Epoch 37/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8239 - acc: 0.6989\n",
            "Epoch 38/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8220 - acc: 0.6994\n",
            "Epoch 39/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.8197 - acc: 0.7006\n",
            "Epoch 40/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8177 - acc: 0.7014\n",
            "Epoch 41/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8155 - acc: 0.7020\n",
            "Epoch 42/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8133 - acc: 0.7029\n",
            "Epoch 43/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8115 - acc: 0.7031\n",
            "Epoch 44/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8098 - acc: 0.7038\n",
            "Epoch 45/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.8084 - acc: 0.7049\n",
            "Epoch 46/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8069 - acc: 0.7046\n",
            "Epoch 47/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8052 - acc: 0.7056\n",
            "Epoch 48/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8044 - acc: 0.7060\n",
            "Epoch 49/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8030 - acc: 0.7064\n",
            "Epoch 50/150\n",
            "365760/365760 [==============================] - 6s 15us/step - loss: 0.8023 - acc: 0.7070\n",
            "Epoch 51/150\n",
            "365760/365760 [==============================] - 6s 15us/step - loss: 0.8010 - acc: 0.7065\n",
            "Epoch 52/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.8001 - acc: 0.7075\n",
            "Epoch 53/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7995 - acc: 0.7078\n",
            "Epoch 54/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7982 - acc: 0.7080\n",
            "Epoch 55/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7974 - acc: 0.7082\n",
            "Epoch 56/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7969 - acc: 0.7087\n",
            "Epoch 57/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7960 - acc: 0.7089\n",
            "Epoch 58/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7956 - acc: 0.7093\n",
            "Epoch 59/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7947 - acc: 0.7094\n",
            "Epoch 60/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7944 - acc: 0.7101\n",
            "Epoch 61/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7936 - acc: 0.7104\n",
            "Epoch 62/150\n",
            "365760/365760 [==============================] - 6s 15us/step - loss: 0.7930 - acc: 0.7104\n",
            "Epoch 63/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7923 - acc: 0.7111\n",
            "Epoch 64/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7917 - acc: 0.7112\n",
            "Epoch 65/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7911 - acc: 0.7119\n",
            "Epoch 66/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7911 - acc: 0.7116\n",
            "Epoch 67/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7900 - acc: 0.7123\n",
            "Epoch 68/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7889 - acc: 0.7127\n",
            "Epoch 69/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7889 - acc: 0.7126\n",
            "Epoch 70/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7879 - acc: 0.7127\n",
            "Epoch 71/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7871 - acc: 0.7130\n",
            "Epoch 72/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7869 - acc: 0.7138\n",
            "Epoch 73/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7857 - acc: 0.7139\n",
            "Epoch 74/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7853 - acc: 0.7143\n",
            "Epoch 75/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7845 - acc: 0.7153\n",
            "Epoch 76/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7842 - acc: 0.7149\n",
            "Epoch 77/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7838 - acc: 0.7151\n",
            "Epoch 78/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7831 - acc: 0.7150\n",
            "Epoch 79/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7825 - acc: 0.7159\n",
            "Epoch 80/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7817 - acc: 0.7160\n",
            "Epoch 81/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7816 - acc: 0.7163\n",
            "Epoch 82/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7809 - acc: 0.7166\n",
            "Epoch 83/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7803 - acc: 0.7173\n",
            "Epoch 84/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7796 - acc: 0.7181\n",
            "Epoch 85/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7788 - acc: 0.7179\n",
            "Epoch 86/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7782 - acc: 0.7184\n",
            "Epoch 87/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7768 - acc: 0.7188\n",
            "Epoch 88/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7766 - acc: 0.7192\n",
            "Epoch 89/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7753 - acc: 0.7191\n",
            "Epoch 90/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7748 - acc: 0.7195\n",
            "Epoch 91/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7737 - acc: 0.7204\n",
            "Epoch 92/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7733 - acc: 0.7201\n",
            "Epoch 93/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7729 - acc: 0.7205\n",
            "Epoch 94/150\n",
            "365760/365760 [==============================] - 7s 19us/step - loss: 0.7724 - acc: 0.7204\n",
            "Epoch 95/150\n",
            "365760/365760 [==============================] - 7s 20us/step - loss: 0.7714 - acc: 0.7211\n",
            "Epoch 96/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7713 - acc: 0.7210\n",
            "Epoch 97/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7705 - acc: 0.7218\n",
            "Epoch 98/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7696 - acc: 0.7219\n",
            "Epoch 99/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7694 - acc: 0.7223\n",
            "Epoch 100/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7683 - acc: 0.7226\n",
            "Epoch 101/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7682 - acc: 0.7224\n",
            "Epoch 102/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7679 - acc: 0.7224\n",
            "Epoch 103/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7673 - acc: 0.7230\n",
            "Epoch 104/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7676 - acc: 0.7228\n",
            "Epoch 105/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7664 - acc: 0.7236\n",
            "Epoch 106/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7660 - acc: 0.7233\n",
            "Epoch 107/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7660 - acc: 0.7236\n",
            "Epoch 108/150\n",
            "365760/365760 [==============================] - 6s 15us/step - loss: 0.7659 - acc: 0.7234\n",
            "Epoch 109/150\n",
            "365760/365760 [==============================] - 6s 16us/step - loss: 0.7654 - acc: 0.7241\n",
            "Epoch 110/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7650 - acc: 0.7240\n",
            "Epoch 111/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7646 - acc: 0.7241\n",
            "Epoch 112/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7640 - acc: 0.7243\n",
            "Epoch 113/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7639 - acc: 0.7247\n",
            "Epoch 114/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7632 - acc: 0.7252\n",
            "Epoch 115/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7631 - acc: 0.7256\n",
            "Epoch 116/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7629 - acc: 0.7257\n",
            "Epoch 117/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7627 - acc: 0.7263\n",
            "Epoch 118/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7619 - acc: 0.7258\n",
            "Epoch 119/150\n",
            "365760/365760 [==============================] - 6s 16us/step - loss: 0.7618 - acc: 0.7263\n",
            "Epoch 120/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7609 - acc: 0.7266\n",
            "Epoch 121/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7609 - acc: 0.7267\n",
            "Epoch 122/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7604 - acc: 0.7268\n",
            "Epoch 123/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7605 - acc: 0.7269\n",
            "Epoch 124/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7602 - acc: 0.7270\n",
            "Epoch 125/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7594 - acc: 0.7278\n",
            "Epoch 126/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7594 - acc: 0.7279\n",
            "Epoch 127/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7591 - acc: 0.7280\n",
            "Epoch 128/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7584 - acc: 0.7280\n",
            "Epoch 129/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7589 - acc: 0.7276\n",
            "Epoch 130/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7584 - acc: 0.7277\n",
            "Epoch 131/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7583 - acc: 0.7279\n",
            "Epoch 132/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7580 - acc: 0.7278\n",
            "Epoch 133/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7578 - acc: 0.7280\n",
            "Epoch 134/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7577 - acc: 0.7276\n",
            "Epoch 135/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7573 - acc: 0.7284\n",
            "Epoch 136/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7574 - acc: 0.7285\n",
            "Epoch 137/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7575 - acc: 0.7284\n",
            "Epoch 138/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7566 - acc: 0.7289\n",
            "Epoch 139/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7566 - acc: 0.7281\n",
            "Epoch 140/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7565 - acc: 0.7288\n",
            "Epoch 141/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7560 - acc: 0.7285\n",
            "Epoch 142/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7561 - acc: 0.7286\n",
            "Epoch 143/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7558 - acc: 0.7282\n",
            "Epoch 144/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7556 - acc: 0.7293\n",
            "Epoch 145/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7559 - acc: 0.7285\n",
            "Epoch 146/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7557 - acc: 0.7286\n",
            "Epoch 147/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7550 - acc: 0.7290\n",
            "Epoch 148/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7554 - acc: 0.7293\n",
            "Epoch 149/150\n",
            "365760/365760 [==============================] - 5s 14us/step - loss: 0.7553 - acc: 0.7290\n",
            "Epoch 150/150\n",
            "365760/365760 [==============================] - 5s 15us/step - loss: 0.7550 - acc: 0.7295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf131d8b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 491
        }
      ]
    },
    {
      "metadata": {
        "id": "BXCn9pqOVqco",
        "colab_type": "code",
        "outputId": "fb320bb4-ceea-4458-b5f2-41233256bc1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred=classifier.predict(X_test)\n",
        "y_pred=y_pred>0.5\n",
        "from sklearn.metrics import confusion_matrix \n",
        "mat=confusion_matrix(Y_test.argmax(axis=1),y_pred.argmax(axis=1))\n",
        "accuracy=np.sum(mat.diagonal())/np.sum(mat)\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6586942257217848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sL1i_cGRnr4D",
        "colab_type": "code",
        "outputId": "e43d5246-3b5e-47b0-fd8b-d46424c328fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "RealTest=pd.read_csv(\"X_test.csv\")\n",
        "RealTest=RealTest.drop('row_id',axis=1)\n",
        "RealTest=RealTest.drop('series_id',axis=1)\n",
        "RealTest=RealTest.drop('measurement_number',axis=1)\n",
        "print(RealTest.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(488448, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EEGVqKSZv9wT",
        "colab_type": "code",
        "outputId": "79042063-976b-4358-d309-44a3f1e61305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "RealTest=sc.transform(RealTest)\n",
        "print(RealTest.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(488448, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZE75fRdCwLp2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Predictions=classifier.predict(RealTest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vNx-g8V3wgnu",
        "colab_type": "code",
        "outputId": "5c7791d4-9539-4617-c913-f2401226b490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "a=np.arange(0,488449,128)\n",
        "fitting=np.array([[0,1,2,3,4,5,6,7,8]])\n",
        "fitting=np.repeat(fitting,3816,axis=0)\n",
        "for i in range(3816):\n",
        "  #temp=(np.sum(y_test_fit[a[i]:a[i+1],:],axis=0)==max(np.sum(y_test_fit[a[i]:a[i+1],:],axis=0)))\n",
        "  #print(temp.shape)\n",
        "  fitting[i,:]=(np.sum(Predictions[a[i]:a[i+1],:],axis=0)==max(np.sum(Predictions[a[i]:a[i+1],:],axis=0)))\n",
        "print(fitting.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3816, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Avs_Wi8hxNCw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Predictions=fitting"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U3U5STuoxWvZ",
        "colab_type": "code",
        "outputId": "d4e56697-a60f-4e7c-86a8-4d73c86a6174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "cell_type": "code",
      "source": [
        "Results=enc.inverse_transform(Predictions)\n",
        "print(Results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['fine_concrete']\n",
            " ['concrete']\n",
            " ['tiled']\n",
            " ...\n",
            " ['hard_tiles_large_space']\n",
            " ['concrete']\n",
            " ['wood']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BCJYu-hAxmTE",
        "colab_type": "code",
        "outputId": "78362d09-d3d1-4c4f-e54e-ec539b6ac7a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "result=pd.DataFrame(Results)\n",
        "#print(result)\n",
        "series_id=pd.DataFrame(np.arange(0,3816,1).reshape(3816,1))\n",
        "#print(series_id.shape)\n",
        "final_res=pd.concat([series_id,result],axis=1)\n",
        "print(final_res.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3816, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LO73TugUx2in",
        "colab_type": "code",
        "outputId": "654f06e8-2791-4feb-d4db-553016762962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1180
        }
      },
      "cell_type": "code",
      "source": [
        "final_res.columns=['series_id','surface']\n",
        "print(final_res)\n",
        "final_res.to_csv('result7.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      series_id                 surface\n",
            "0             0           fine_concrete\n",
            "1             1                concrete\n",
            "2             2                   tiled\n",
            "3             3                  carpet\n",
            "4             4                soft_pvc\n",
            "5             5                concrete\n",
            "6             6                concrete\n",
            "7             7                concrete\n",
            "8             8                concrete\n",
            "9             9                  carpet\n",
            "10           10                soft_pvc\n",
            "11           11                soft_pvc\n",
            "12           12  hard_tiles_large_space\n",
            "13           13              soft_tiles\n",
            "14           14                    wood\n",
            "15           15                    wood\n",
            "16           16                concrete\n",
            "17           17                  carpet\n",
            "18           18                    wood\n",
            "19           19           fine_concrete\n",
            "20           20                soft_pvc\n",
            "21           21                concrete\n",
            "22           22                concrete\n",
            "23           23  hard_tiles_large_space\n",
            "24           24                concrete\n",
            "25           25                   tiled\n",
            "26           26                concrete\n",
            "27           27                   tiled\n",
            "28           28                    wood\n",
            "29           29                concrete\n",
            "...         ...                     ...\n",
            "3786       3786                soft_pvc\n",
            "3787       3787                concrete\n",
            "3788       3788  hard_tiles_large_space\n",
            "3789       3789                concrete\n",
            "3790       3790           fine_concrete\n",
            "3791       3791  hard_tiles_large_space\n",
            "3792       3792                    wood\n",
            "3793       3793                    wood\n",
            "3794       3794                concrete\n",
            "3795       3795                concrete\n",
            "3796       3796  hard_tiles_large_space\n",
            "3797       3797                concrete\n",
            "3798       3798                    wood\n",
            "3799       3799                concrete\n",
            "3800       3800                concrete\n",
            "3801       3801                  carpet\n",
            "3802       3802           fine_concrete\n",
            "3803       3803                concrete\n",
            "3804       3804                concrete\n",
            "3805       3805              soft_tiles\n",
            "3806       3806                concrete\n",
            "3807       3807                soft_pvc\n",
            "3808       3808                   tiled\n",
            "3809       3809                   tiled\n",
            "3810       3810                concrete\n",
            "3811       3811                    wood\n",
            "3812       3812              soft_tiles\n",
            "3813       3813  hard_tiles_large_space\n",
            "3814       3814                concrete\n",
            "3815       3815                    wood\n",
            "\n",
            "[3816 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EBYkxsQlyEcT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}